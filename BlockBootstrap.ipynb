{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "import itertools\n",
    "from math import factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back = 1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), :]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, :])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateData(data, perm):\n",
    "    n = data.shape[0]\n",
    "    blockSize = n // len(perm)\n",
    "    dataSet = np.zeros(data[0].shape)\n",
    "    for i in perm:\n",
    "        block = data[i*blockSize:(i+1)*blockSize]\n",
    "#         print(block, end='\\n\\n')\n",
    "        dataSet = np.vstack((dataSet, block))\n",
    "    dataSet = dataSet[1:]\n",
    "    return dataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       open     close\n",
      "0  390.4551  393.0777\n",
      "1  389.5892  391.6012\n",
      "2  391.2659  390.7403\n",
      "3  390.4551  391.8214\n",
      "4  390.2549  394.3039\n",
      "(1259, 2)\n"
     ]
    }
   ],
   "source": [
    "# dataframe = read_csv('sp500.csv')\n",
    "fields = ['open', 'close']\n",
    "dataframe = read_csv('GOOGL_data.csv', skipinitialspace = True, squeeze = True, usecols = fields)\n",
    "\n",
    "print(dataframe.head())\n",
    "data = np.array(dataframe)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00683718 0.01210825]\n",
      " [0.0057589  0.01027231]\n",
      " [0.00784685 0.00920184]\n",
      " [0.00683718 0.01054612]\n",
      " [0.00658788 0.01363296]]\n"
     ]
    }
   ],
   "source": [
    "# dataset = dataset.astype('float32')\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data = scaler.fit_transform(data)\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "906\n",
      "353\n"
     ]
    }
   ],
   "source": [
    "split = 0.72\n",
    "trainSize = int(len(data)*split)\n",
    "testSize = len(data)-trainSize\n",
    "print(trainSize)\n",
    "print(testSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151\n"
     ]
    }
   ],
   "source": [
    "numInterval = 6\n",
    "blockSize = trainSize//numInterval\n",
    "print(blockSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00683718 0.01210825]\n",
      " [0.0057589  0.01027231]\n",
      " [0.00784685 0.00920184]\n",
      " [0.00683718 0.01054612]\n",
      " [0.00658788 0.01363296]]\n"
     ]
    }
   ],
   "source": [
    "    train = data[0:trainSize,:]\n",
    "    test = data[trainSize:len(data),:]\n",
    "    print(train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "902/902 [==============================] - 18s 20ms/step - loss: 0.0012\n",
      "Train Score: 21.46 RMSE\n",
      "Test Score: 39.50 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 5s 6ms/step - loss: 0.0014\n",
      "Train Score: 17.21 RMSE\n",
      "Test Score: 13.76 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 5s 6ms/step - loss: 0.0013\n",
      "Train Score: 17.16 RMSE\n",
      "Test Score: 21.05 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 6ms/step - loss: 9.3668e-04\n",
      "Train Score: 15.08 RMSE\n",
      "Test Score: 13.75 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 6ms/step - loss: 9.6481e-04\n",
      "Train Score: 17.95 RMSE\n",
      "Test Score: 15.23 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 6ms/step - loss: 0.0015\n",
      "Train Score: 18.96 RMSE\n",
      "Test Score: 22.91 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 6ms/step - loss: 0.0011\n",
      "Train Score: 15.82 RMSE\n",
      "Test Score: 25.87 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 6ms/step - loss: 0.0012\n",
      "Train Score: 17.90 RMSE\n",
      "Test Score: 19.90 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0016\n",
      "Train Score: 15.89 RMSE\n",
      "Test Score: 14.57 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0015\n",
      "Train Score: 19.94 RMSE\n",
      "Test Score: 31.41 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0018\n",
      "Train Score: 19.84 RMSE\n",
      "Test Score: 27.01 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0012\n",
      "Train Score: 20.96 RMSE\n",
      "Test Score: 30.57 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0012\n",
      "Train Score: 14.98 RMSE\n",
      "Test Score: 13.68 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0013\n",
      "Train Score: 22.94 RMSE\n",
      "Test Score: 27.29 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0012\n",
      "Train Score: 15.91 RMSE\n",
      "Test Score: 17.07 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 6s 7ms/step - loss: 0.0019\n",
      "Train Score: 18.69 RMSE\n",
      "Test Score: 14.52 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 7ms/step - loss: 0.0015\n",
      "Train Score: 16.41 RMSE\n",
      "Test Score: 15.95 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 7ms/step - loss: 9.0636e-04\n",
      "Train Score: 15.63 RMSE\n",
      "Test Score: 16.09 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0015\n",
      "Train Score: 17.84 RMSE\n",
      "Test Score: 19.12 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 7ms/step - loss: 0.0016\n",
      "Train Score: 19.32 RMSE\n",
      "Test Score: 25.20 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 7ms/step - loss: 0.0014\n",
      "Train Score: 20.00 RMSE\n",
      "Test Score: 29.88 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 7ms/step - loss: 0.0014\n",
      "Train Score: 18.04 RMSE\n",
      "Test Score: 18.91 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0014\n",
      "Train Score: 18.26 RMSE\n",
      "Test Score: 20.75 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0016\n",
      "Train Score: 18.49 RMSE\n",
      "Test Score: 15.25 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0013\n",
      "Train Score: 13.08 RMSE\n",
      "Test Score: 13.83 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0015\n",
      "Train Score: 17.42 RMSE\n",
      "Test Score: 17.00 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0014\n",
      "Train Score: 16.77 RMSE\n",
      "Test Score: 21.02 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0014\n",
      "Train Score: 18.51 RMSE\n",
      "Test Score: 25.84 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0015\n",
      "Train Score: 18.13 RMSE\n",
      "Test Score: 14.78 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0024\n",
      "Train Score: 19.91 RMSE\n",
      "Test Score: 16.26 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 7.4004e-04\n",
      "Train Score: 13.49 RMSE\n",
      "Test Score: 13.98 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 7s 8ms/step - loss: 0.0019\n",
      "Train Score: 18.06 RMSE\n",
      "Test Score: 14.98 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 8ms/step - loss: 0.0015\n",
      "Train Score: 49.24 RMSE\n",
      "Test Score: 72.47 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0020\n",
      "Train Score: 19.23 RMSE\n",
      "Test Score: 16.46 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0018\n",
      "Train Score: 19.98 RMSE\n",
      "Test Score: 15.17 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0015\n",
      "Train Score: 27.67 RMSE\n",
      "Test Score: 41.67 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 9ms/step - loss: 0.0018\n",
      "Train Score: 17.99 RMSE\n",
      "Test Score: 14.44 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0022\n",
      "Train Score: 22.77 RMSE\n",
      "Test Score: 15.97 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 8.2819e-04\n",
      "Train Score: 15.84 RMSE\n",
      "Test Score: 14.41 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0022\n",
      "Train Score: 21.33 RMSE\n",
      "Test Score: 16.82 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0015\n",
      "Train Score: 21.16 RMSE\n",
      "Test Score: 25.59 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0018\n",
      "Train Score: 19.28 RMSE\n",
      "Test Score: 19.96 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0021\n",
      "Train Score: 21.27 RMSE\n",
      "Test Score: 16.57 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0020\n",
      "Train Score: 21.85 RMSE\n",
      "Test Score: 18.25 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 8s 9ms/step - loss: 0.0012\n",
      "Train Score: 17.75 RMSE\n",
      "Test Score: 14.06 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0022\n",
      "Train Score: 20.70 RMSE\n",
      "Test Score: 15.25 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0017\n",
      "Train Score: 20.42 RMSE\n",
      "Test Score: 13.61 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0015\n",
      "Train Score: 18.90 RMSE\n",
      "Test Score: 15.51 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0011\n",
      "Train Score: 20.58 RMSE\n",
      "Test Score: 27.46 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0016\n",
      "Train Score: 17.86 RMSE\n",
      "Test Score: 13.41 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0010\n",
      "Train Score: 16.26 RMSE\n",
      "Test Score: 14.97 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0016\n",
      "Train Score: 17.38 RMSE\n",
      "Test Score: 17.14 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0018\n",
      "Train Score: 18.71 RMSE\n",
      "Test Score: 16.63 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0017\n",
      "Train Score: 25.54 RMSE\n",
      "Test Score: 54.93 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0014\n",
      "Train Score: 15.96 RMSE\n",
      "Test Score: 28.47 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 9s 10ms/step - loss: 0.0018\n",
      "Train Score: 19.54 RMSE\n",
      "Test Score: 15.57 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0013\n",
      "Train Score: 28.61 RMSE\n",
      "Test Score: 58.87 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0017\n",
      "Train Score: 26.67 RMSE\n",
      "Test Score: 39.73 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0018\n",
      "Train Score: 21.27 RMSE\n",
      "Test Score: 20.99 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0020\n",
      "Train Score: 23.20 RMSE\n",
      "Test Score: 15.63 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0012\n",
      "Train Score: 18.45 RMSE\n",
      "Test Score: 14.46 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0017\n",
      "Train Score: 20.20 RMSE\n",
      "Test Score: 24.61 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0017\n",
      "Train Score: 16.30 RMSE\n",
      "Test Score: 14.11 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0014\n",
      "Train Score: 21.34 RMSE\n",
      "Test Score: 15.11 RMSE\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0016\n",
      "Train Score: 19.28 RMSE\n",
      "Test Score: 13.75 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0013\n",
      "Train Score: 16.49 RMSE\n",
      "Test Score: 17.94 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0014\n",
      "Train Score: 19.66 RMSE\n",
      "Test Score: 15.83 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 11ms/step - loss: 0.0015\n",
      "Train Score: 21.74 RMSE\n",
      "Test Score: 18.57 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 10s 12ms/step - loss: 0.0010\n",
      "Train Score: 18.98 RMSE\n",
      "Test Score: 17.22 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 12ms/step - loss: 0.0018\n",
      "Train Score: 20.88 RMSE\n",
      "Test Score: 15.28 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 12ms/step - loss: 0.0015\n",
      "Train Score: 20.22 RMSE\n",
      "Test Score: 15.16 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 12ms/step - loss: 0.0014\n",
      "Train Score: 19.30 RMSE\n",
      "Test Score: 23.19 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 12ms/step - loss: 0.0015\n",
      "Train Score: 17.90 RMSE\n",
      "Test Score: 13.52 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 12ms/step - loss: 0.0019\n",
      "Train Score: 23.09 RMSE\n",
      "Test Score: 34.46 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 13ms/step - loss: 0.0020\n",
      "Train Score: 18.28 RMSE\n",
      "Test Score: 15.47 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 12ms/step - loss: 0.0020\n",
      "Train Score: 22.68 RMSE\n",
      "Test Score: 35.04 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 13ms/step - loss: 0.0022\n",
      "Train Score: 20.46 RMSE\n",
      "Test Score: 15.99 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 11s 13ms/step - loss: 0.0016\n",
      "Train Score: 20.51 RMSE\n",
      "Test Score: 15.25 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 13ms/step - loss: 0.0015\n",
      "Train Score: 18.48 RMSE\n",
      "Test Score: 14.76 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 13ms/step - loss: 0.0012\n",
      "Train Score: 20.04 RMSE\n",
      "Test Score: 18.34 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 13ms/step - loss: 0.0015\n",
      "Train Score: 17.27 RMSE\n",
      "Test Score: 15.78 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 13ms/step - loss: 0.0014\n",
      "Train Score: 21.73 RMSE\n",
      "Test Score: 17.49 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 13ms/step - loss: 0.0016\n",
      "Train Score: 21.24 RMSE\n",
      "Test Score: 13.75 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 13ms/step - loss: 0.0017\n",
      "Train Score: 19.05 RMSE\n",
      "Test Score: 13.51 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 14ms/step - loss: 0.0012\n",
      "Train Score: 16.35 RMSE\n",
      "Test Score: 17.68 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 12s 14ms/step - loss: 0.0015\n",
      "Train Score: 19.31 RMSE\n",
      "Test Score: 19.40 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 14ms/step - loss: 0.0015\n",
      "Train Score: 17.71 RMSE\n",
      "Test Score: 20.37 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 15ms/step - loss: 0.0016\n",
      "Train Score: 22.77 RMSE\n",
      "Test Score: 25.43 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 14ms/step - loss: 0.0014\n",
      "Train Score: 21.65 RMSE\n",
      "Test Score: 23.59 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 14ms/step - loss: 0.0014\n",
      "Train Score: 20.02 RMSE\n",
      "Test Score: 17.07 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 14ms/step - loss: 0.0014\n",
      "Train Score: 18.58 RMSE\n",
      "Test Score: 14.35 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 14ms/step - loss: 0.0017\n",
      "Train Score: 19.83 RMSE\n",
      "Test Score: 26.68 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 15ms/step - loss: 0.0014\n",
      "Train Score: 17.27 RMSE\n",
      "Test Score: 15.74 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 15ms/step - loss: 0.0012\n",
      "Train Score: 17.47 RMSE\n",
      "Test Score: 13.70 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 15ms/step - loss: 0.0023\n",
      "Train Score: 17.07 RMSE\n",
      "Test Score: 15.31 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 15ms/step - loss: 0.0017\n",
      "Train Score: 18.52 RMSE\n",
      "Test Score: 17.98 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 13s 15ms/step - loss: 0.0019\n",
      "Train Score: 26.32 RMSE\n",
      "Test Score: 22.45 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 15ms/step - loss: 0.0015\n",
      "Train Score: 21.23 RMSE\n",
      "Test Score: 15.99 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 15ms/step - loss: 0.0016\n",
      "Train Score: 21.08 RMSE\n",
      "Test Score: 15.71 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 15ms/step - loss: 0.0018\n",
      "Train Score: 21.88 RMSE\n",
      "Test Score: 18.82 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 15ms/step - loss: 0.0017\n",
      "Train Score: 22.73 RMSE\n",
      "Test Score: 23.44 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 15ms/step - loss: 0.0022\n",
      "Train Score: 24.52 RMSE\n",
      "Test Score: 19.39 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 16ms/step - loss: 0.0016\n",
      "Train Score: 24.56 RMSE\n",
      "Test Score: 44.20 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 16ms/step - loss: 0.0023\n",
      "Train Score: 20.25 RMSE\n",
      "Test Score: 13.49 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 16ms/step - loss: 0.0017\n",
      "Train Score: 19.18 RMSE\n",
      "Test Score: 14.60 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 16ms/step - loss: 0.0021\n",
      "Train Score: 22.51 RMSE\n",
      "Test Score: 18.07 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 14s 16ms/step - loss: 0.0020\n",
      "Train Score: 21.39 RMSE\n",
      "Test Score: 14.18 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 16ms/step - loss: 0.0018\n",
      "Train Score: 24.69 RMSE\n",
      "Test Score: 14.53 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 16ms/step - loss: 0.0015\n",
      "Train Score: 18.90 RMSE\n",
      "Test Score: 15.02 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 17ms/step - loss: 0.0021\n",
      "Train Score: 20.77 RMSE\n",
      "Test Score: 21.49 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 17ms/step - loss: 0.0014\n",
      "Train Score: 19.11 RMSE\n",
      "Test Score: 16.65 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 17ms/step - loss: 0.0019\n",
      "Train Score: 23.30 RMSE\n",
      "Test Score: 16.69 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 17ms/step - loss: 0.0020\n",
      "Train Score: 21.09 RMSE\n",
      "Test Score: 16.04 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 16s 17ms/step - loss: 0.0025\n",
      "Train Score: 20.78 RMSE\n",
      "Test Score: 13.89 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 17ms/step - loss: 0.0023\n",
      "Train Score: 23.28 RMSE\n",
      "Test Score: 27.70 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 15s 17ms/step - loss: 0.0020\n",
      "Train Score: 21.45 RMSE\n",
      "Test Score: 16.24 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 16s 18ms/step - loss: 0.0016\n",
      "Train Score: 20.90 RMSE\n",
      "Test Score: 22.51 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 16s 17ms/step - loss: 0.0015\n",
      "Train Score: 19.63 RMSE\n",
      "Test Score: 16.56 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 16s 17ms/step - loss: 0.0017\n",
      "Train Score: 20.78 RMSE\n",
      "Test Score: 17.48 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 16s 18ms/step - loss: 0.0014\n",
      "Train Score: 20.83 RMSE\n",
      "Test Score: 14.37 RMSE\n",
      "Epoch 1/1\n",
      "902/902 [==============================] - 16s 18ms/step - loss: 0.0011\n",
      "Train Score: 15.80 RMSE\n",
      "Test Score: 18.01 RMSE\n",
      "Epoch 1/1\n",
      "598/902 [==================>...........] - ETA: 7s - loss: 0.0017"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-7f7d86513bd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m#     tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#     model.fit(trainX, trainY, epochs=epoch, batch_size=1, verbose=1, callbacks=[tensorboard])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtrainPredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.5/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/ML/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "permutations = itertools.permutations(range(numInterval))\n",
    "testBand = []\n",
    "for perm in permutations:\n",
    "    trainSet = generateData(train, perm)\n",
    "    trainSet = np.reshape(trainSet, trainSet.shape)\n",
    "    shuffleData = np.vstack((trainSet, test))\n",
    "\n",
    "    lookBack = 3\n",
    "    trainX, trainY = create_dataset(trainSet, lookBack)\n",
    "    testX, testY = create_dataset(test, lookBack)\n",
    "\n",
    "    # trainX = np.reshape(trainX, (trainX.shape[0], 2, trainX.shape[1]))\n",
    "    # testX = np.reshape(testX, (testX.shape[0], 2, testX.shape[1]))\n",
    "\n",
    "    units = 100\n",
    "    drop = 0.2\n",
    "    epoch = 10\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units, input_shape=(lookBack, 2)))\n",
    "    model.add(Dense(2))\n",
    "    model.compile(loss='mean_squared_error', optimizer='nadam')\n",
    "#     model.summary()\n",
    "#     tensorboard = TensorBoard(log_dir=\"logs/{}\".format(time()))\n",
    "#     model.fit(trainX, trainY, epochs=epoch, batch_size=1, verbose=1, callbacks=[tensorboard])\n",
    "    model.fit(trainX, trainY, epochs=epoch, batch_size=1, verbose=1)\n",
    "\n",
    "    trainPredict = model.predict(trainX)\n",
    "    testPredict = model.predict(testX)\n",
    "\n",
    "    trainPredict = scaler.inverse_transform(trainPredict)\n",
    "    trainY = scaler.inverse_transform(trainY)\n",
    "    testPredict = scaler.inverse_transform(testPredict)\n",
    "    testY = scaler.inverse_transform(testY)\n",
    "\n",
    "    trainScore = math.sqrt(mean_squared_error(trainY, trainPredict))\n",
    "    print('Train Score: %.2f RMSE' % (trainScore))\n",
    "    testScore = math.sqrt(mean_squared_error(testY, testPredict))\n",
    "    print('Test Score: %.2f RMSE' % (testScore))\n",
    "\n",
    "    trainPredictPlot = np.empty_like(shuffleData)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[lookBack:len(trainPredict)+lookBack, :] = trainPredict\n",
    "\n",
    "    testPredictPlot = np.empty_like(shuffleData)\n",
    "    testPredictPlot[:, :] = np.nan\n",
    "    testPredictPlot[len(trainPredict)+(lookBack*2)+1:len(data)-1, :] = testPredict\n",
    "    testBand.append(testPredict)\n",
    "#     testPredictPlot[len(trainPredict)+(lookBack*2)+1:len(data)-1, :] = testPredict\n",
    "\n",
    "    col = 0\n",
    "    testPlot = np.empty_like(trainSet)\n",
    "    testPlot[:, :] = 0\n",
    "    testPlot = np.vstack((testPlot, test))\n",
    "#     plt.plot(scaler.inverse_transform(shuffleData)[:,col])\n",
    "#     plt.plot(trainPredictPlot[:,col], color = 'orange')\n",
    "#     plt.plot(testPredictPlot[:,col], color = 'green')\n",
    "plt.plot(scaler.inverse_transform(testPlot)[:,col], color = 'blue')\n",
    "plt.title('Epoch = %d Train = %.2f Test = %.2f' % (epoch, trainScore, testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBand = np.array(testBand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testBand = np.reshape(testBand, (testBand.shape))\n",
    "# print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[396.00574 395.12387]\n",
      "[1.7265694 2.095474 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(testBand[:,0,:], axis = 0))\n",
    "print(np.std(testBand[:,0,:], axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_alpha = 1.96\n",
    "n = factorial(numInterval)\n",
    "\n",
    "confInterval = []\n",
    "\n",
    "for i in range(testBand.shape[1]):\n",
    "    X = testBand[:, i, :]\n",
    "    xBar = np.mean(X, axis = 0)\n",
    "    s = np.std(X, axis = 0)\n",
    "    l = xBar - 1.96*s/(n**0,.5)\n",
    "    r = xBar + 1.96*s/(n**0,.5)\n",
    "    pair = [l, r]\n",
    "    confInterval.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confInterval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50 51 52 53 54 55 56 57 58 59 60]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "col = 0\n",
    "offset = len(trainPredict)+(lookBack*2)+2\n",
    "lower = []\n",
    "upper = []\n",
    "for i in range(len(confInterval)):\n",
    "#     X = [i, i]\n",
    "#     Y = [confInterval[i][0][0], confInterval[i][1][0]]\n",
    "    lower.append(confInterval[i][0][0])\n",
    "    upper.append(confInterval[i][1][0])\n",
    "# XLower = np.array(range(offset+1, data.shape[0], blockSize//n))\n",
    "# XUpper = np.array(range(offset+1, data.shape[0], blockSize//n))\n",
    "XLower = np.array(range(offset+1, offset+1+testBand.shape[1]))\n",
    "XUpper = np.array(range(offset+1, offset+1+testBand.shape[1]))\n",
    "print(XLower)\n",
    "# print(np.array(upper)+offset)\n",
    "# plt.plot(lower, XLower)\n",
    "# plt.plot(upper, XUpper)\n",
    "plt.plot(XLower, lower)\n",
    "plt.plot(XUpper, upper)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(range(offset+1, data.shape[0], blockSize//n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
